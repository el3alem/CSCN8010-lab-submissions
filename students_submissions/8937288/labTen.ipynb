{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student name: Omar Elalem no.:8937288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve,auc\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up paths\n",
    "\n",
    "data_folder = pathlib.Path( 'D:\\conestoga\\SubMLA\\CSCN8010-lab-submissions\\data')\n",
    "\n",
    "\n",
    "train_dir = data_folder / \"train\"\n",
    "valid_dir = data_folder / \"valid\"\n",
    "test_dir = data_folder / \"test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RUFOUS TREPE', 263), ('HOUSE FINCH', 248), ('D-ARNAUDS BARBET', 233)]\n",
      "Top three classes with the highest number of images:\n",
      "RUFOUS TREPE: 263 images\n",
      "HOUSE FINCH: 248 images\n",
      "D-ARNAUDS BARBET: 233 images\n",
      "['RUFOUS TREPE', 'HOUSE FINCH', 'D-ARNAUDS BARBET']\n"
     ]
    }
   ],
   "source": [
    "class_folders = [folder for folder in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, folder))]\n",
    "class_image_counts = {}\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(train_dir, class_folder)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    class_image_counts[class_folder] = num_images\n",
    "sorted_classes = sorted(class_image_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_three_classes = sorted_classes[:3]\n",
    "print(top_three_classes)\n",
    "print(\"Top three classes with the highest number of images:\")\n",
    "classes = ['class1', 'class2', 'class3']\n",
    "countt=0\n",
    "for class_name, count in top_three_classes:\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "    classes[countt]=top_three_classes[countt][0]\n",
    "    countt=countt+1\n",
    "print(classes)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for species in os.listdir(train_dir):\n",
    "    if species not in classes:\n",
    "        delete_path_train = os.path.join(train_dir, species)\n",
    "        if os.path.isdir(delete_path_train):\n",
    "            shutil.rmtree(delete_path_train)\n",
    "\n",
    "for species in os.listdir(test_dir):\n",
    "    if species not in classes:\n",
    "        delete_path_test = os.path.join(test_dir, species)\n",
    "        if os.path.isdir(delete_path_test):\n",
    "            shutil.rmtree(delete_path_test)\n",
    "\n",
    "for species in os.listdir(valid_dir):\n",
    "    if species not in classes:\n",
    "        delete_path_valid = os.path.join(valid_dir, species)\n",
    "        if os.path.isdir(delete_path_valid):\n",
    "            shutil.rmtree(delete_path_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 744 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "datagene = ImageDataGenerator( rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,   \n",
    "    fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "train_generator = datagene.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # VGG16 input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=classes\n",
    ")\n",
    "valid_generator =datagene.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = datagene.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RUFOUS TREPE', 263), ('HOUSE FINCH', 248), ('D-ARNAUDS BARBET', 233)]\n",
      "Top three classes with the highest number of images:\n",
      "RUFOUS TREPE: 263 images\n",
      "HOUSE FINCH: 248 images\n",
      "D-ARNAUDS BARBET: 233 images\n"
     ]
    }
   ],
   "source": [
    "class_folders = [folder for folder in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, folder))]\n",
    "class_image_counts = {}\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(train_dir, class_folder)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    class_image_counts[class_folder] = num_images\n",
    "sorted_classes = sorted(class_image_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_three_classes = sorted_classes[:3]\n",
    "print(top_three_classes)\n",
    "print(\"Top three classes with the highest number of images:\")\n",
    "for class_name, count in top_three_classes:\n",
    "    print(f\"{class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_generator: 24\n"
     ]
    }
   ],
   "source": [
    "num_batches = len(train_generator)\n",
    "print(\"Number of batches in train_generator:\", num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    image, label = train_generator.next()\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image[0].astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    image, label = train_generator.next()\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image[0].astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 18s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bas_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "bas_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,978,883\n",
      "Trainable params: 14,978,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = bas_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=bas_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,978,883\n",
      "Trainable params: 14,978,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training the model using fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/24 [=================>............] - ETA: 49:57 - loss: 1.8504 - accuracy: 0.3487"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,epochs=10,validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating the model and getting th metrix the precision recall curve and calculating AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd = model.predict(valid_generator)\n",
    "y_pred_tre = valid_generator.classes\n",
    "y_pred_cls = np.argmax(y_prd, axis=1)\n",
    "accuracy = accuracy_score(y_pred_cls, y_pred_cls)\n",
    "confusion_mat = confusion_matrix(y_pred_tre, y_pred_cls)\n",
    "confusion_mat\n",
    "report = classification_report(y_pred_tre, y_pred_cls,target_names=valid_generator.class_indices.keys())\n",
    "fpr, tpr, thresholds = roc_curve(y_pred_tre, y_prd[:, 0], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"ROC AUC: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
